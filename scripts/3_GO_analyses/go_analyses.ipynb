{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f459fa65",
   "metadata": {},
   "source": [
    "# GO annotation analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58710564",
   "metadata": {},
   "source": [
    "1. Find GO annotations in GFF file for each genome\n",
    "2. Run through the files and come up with a list of unique GO IDs\n",
    "3. Create a table with presence/absence for all genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265914d",
   "metadata": {},
   "source": [
    "### 1. Find GO annotations in GFF file for each genome, save each list to an individual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf7e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_modeling_accessions():\n",
    "    with open(\"results/2_JGIgold_KEGG_anayses_out/05_genome_feature_matrix.tsv\", \"r\", newline=\"\") as rf:\n",
    "        next(rf)\n",
    "        reader = csv.reader(rf, delimiter=\"\\t\")\n",
    "        accessions = [row[0] for row in reader]\n",
    "    return accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41caa306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_go_annotations(gff_file):\n",
    "    go_terms = set([])\n",
    "    with open(gff_file, \"r\") as rf:\n",
    "        for line in rf:\n",
    "            if not line.startswith(\"#\"):\n",
    "                fields = line.split(\"\\t\")[-1].split(\";\")\n",
    "                for field in fields:\n",
    "                    if field.startswith(\"Ontology_term\"):\n",
    "                        field_data = field[field.index(\"=\")+1:]\n",
    "                        go_terms.update([term[3:] for term in field_data.split(\",\")])\n",
    "\n",
    "    genome = gff_file.split(\"/\")[-2]\n",
    "    outfile = \"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists/\" + genome + \".txt\"\n",
    "    with open(outfile, \"w\") as wf:\n",
    "        for term in go_terms:\n",
    "            wf.write(term + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734aa6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = \"GCF_030643905.1\"\n",
    "test_path = \"/n/scratch/users/b/byc014/github/bac_genome_constraint/data/ncbi/assemblies/GCF_030643905.1/genomic.gff\"\n",
    "\n",
    "find_go_annotations(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4a3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "os.chdir(\"/n/scratch/users/a/aip485/bac_genome_constraint/\")\n",
    "modeling_accessions = get_modeling_accessions()\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/missing_genomes.txt\", \"w\") as wf:\n",
    "    for acc in modeling_accessions:\n",
    "        gff_file = f\"/n/scratch/users/b/byc014/github/bac_genome_constraint/data/ncbi/assemblies/{acc}/genomic.gff\"\n",
    "        if os.path.exists(gff_file):\n",
    "            find_go_annotations(gff_file)\n",
    "        else:\n",
    "            print(\"Missing\", acc)\n",
    "            wf.write(acc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b221cf",
   "metadata": {},
   "source": [
    "### 2. Run through the files and come up with a list of unique GO IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4710b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "unique_terms = set([])\n",
    "to_skip = []\n",
    "for go_list_file in glob.iglob(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists/*.txt\"):\n",
    "    with open(go_list_file, \"r\") as rf:\n",
    "        genome_terms = [int(line.strip()) for line in rf]\n",
    "        if len(genome_terms) == 0:\n",
    "            to_skip.append(os.path.basename(go_list_file))\n",
    "        unique_terms.update(genome_terms)\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/unique_terms.txt\", \"w\") as wf:\n",
    "    for term in sorted(unique_terms):\n",
    "        wf.write(f\"{term:07d}\\n\")\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/missing_terms.txt\", \"w\") as wf:\n",
    "    for genome in to_skip:\n",
    "        wf.write(genome + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8384a10",
   "metadata": {},
   "source": [
    "#### 2.1 Remove files without any GO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b44ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/missing_terms.txt\", \"r\") as rf:\n",
    "    missing_terms = [line.strip() for line in rf]\n",
    "\n",
    "for basename in missing_terms:\n",
    "    fn = \"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists/\" + basename\n",
    "    os.remove(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81653477",
   "metadata": {},
   "source": [
    "### 3. Create a table with presence/absence for all genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae7be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/unique_terms.txt\", \"r\") as rf:\n",
    "    unique_terms = [line.strip() for line in rf]\n",
    "\n",
    "genome_match_string = \"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists/*.txt\"\n",
    "genome_files = [fn for fn in glob.iglob(genome_match_string) ]\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/presence_absence_table.txt\", \"w\") as wf:\n",
    "\n",
    "    # Write header\n",
    "    wf.write(\"Genome\\t\" + \"\\t\".join(unique_terms) + \"\\n\")\n",
    "\n",
    "    for fn in glob.iglob(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists/*.txt\"):\n",
    "\n",
    "        basename = os.path.basename(fn)\n",
    "        \n",
    "        with open(fn, \"r\") as rf:\n",
    "            genome_terms = [line.strip() for line in rf]\n",
    "        presence_absence = [\"1\" if term in genome_terms else \"0\" for term in unique_terms]\n",
    "        wf.write(basename[:-4] + \"\\t\" + \"\\t\".join(presence_absence) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383a62e",
   "metadata": {},
   "source": [
    "### Create list of ubiquitous terms (present in >95% of genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4398437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3088 files, cutoff is 2933.6\n",
      "334 ubiquitous terms\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/unique_terms.txt\", \"r\") as rf:\n",
    "    unique_terms = [line.strip() for line in rf]\n",
    "\n",
    "term_counts = {term: 0 for term in unique_terms}\n",
    "\n",
    "filenames = glob.glob(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists/*.txt\")\n",
    "for fn in filenames:\n",
    "    basename = os.path.basename(fn)\n",
    "    with open(fn, \"r\") as rf:\n",
    "        for line in rf:\n",
    "            term = line.strip()\n",
    "            term_counts[term] += 1\n",
    "\n",
    "abundance_cutoff = len(filenames) * 0.95\n",
    "print(len(filenames), \"files, cutoff is\", abundance_cutoff)\n",
    "\n",
    "ubiquitous_terms_count = 0\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/ubiquitous_terms.txt\", \"w\") as wf:\n",
    "    for term in unique_terms:\n",
    "        if term_counts[term] >= abundance_cutoff:\n",
    "            wf.write(term + \"\\n\")\n",
    "            ubiquitous_terms_count += 1\n",
    "\n",
    "print(ubiquitous_terms_count, \"ubiquitous terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b519b",
   "metadata": {},
   "source": [
    "### Generate per-genome counts for all terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c21be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_go_annotations_with_counts(gff_file):\n",
    "    go_terms = {}\n",
    "    with open(gff_file, \"r\") as rf:\n",
    "        for line in rf:\n",
    "            if not line.startswith(\"#\"):\n",
    "                fields = line.split(\"\\t\")[-1].split(\";\")\n",
    "                for field in fields:\n",
    "                    if field.startswith(\"Ontology_term\"):\n",
    "                        field_data = field[field.index(\"=\")+1:]\n",
    "                        for full_term in field_data.split(\",\"):\n",
    "                            term = full_term[3:]\n",
    "                            go_terms[term] = go_terms.get(term, 0) + 1\n",
    "\n",
    "    genome = gff_file.split(\"/\")[-2]\n",
    "    outfile = \"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists_with_counts/\" + genome + \".txt\"\n",
    "    with open(outfile, \"w\") as wf:\n",
    "        for term, count in go_terms.items():\n",
    "            wf.write(f\"{term}\\t{count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecc264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "modeling_accessions = get_modeling_accessions()\n",
    "\n",
    "for acc in modeling_accessions:\n",
    "    gff_file = f\"/n/scratch/users/b/byc014/github/bac_genome_constraint/data/ncbi/assemblies/{acc}/genomic.gff\"\n",
    "    find_go_annotations_with_counts(gff_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d54c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/missing_terms.txt\", \"r\") as rf:\n",
    "    missing_terms = [line.strip() for line in rf]\n",
    "\n",
    "for basename in missing_terms:\n",
    "    fn = \"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists_with_counts/\" + basename\n",
    "    os.remove(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f063a",
   "metadata": {},
   "source": [
    "### Generate table of ubiquitous term counts for all genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fd3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/ubiquitous_terms.txt\", \"r\") as rf:\n",
    "    ubiquitous_terms = [line.strip() for line in rf]\n",
    "term_index_map = {term: i for i, term in enumerate(ubiquitous_terms)}\n",
    "ubiquitous_term_count = len(ubiquitous_terms)\n",
    "\n",
    "with open(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/ubiquitous_counts_table.txt\", \"w\") as wf:\n",
    "    wf.write(\"Genome\\t\" + \"\\t\".join(ubiquitous_terms) + \"\\n\")\n",
    "    for fn in glob.iglob(\"/n/scratch/users/a/aip485/bac_genome_constraint/results/3_GO_analyses/GO_lists_with_counts/*.txt\"):\n",
    "        basename = os.path.basename(fn)\n",
    "\n",
    "        counts_list = ['0' for i in range(ubiquitous_term_count)]\n",
    "        with open(fn, \"r\") as rf:\n",
    "            for line in rf:\n",
    "                fields = line.strip().split(\"\\t\")\n",
    "                if fields[0] in term_index_map:\n",
    "                    counts_list[term_index_map[fields[0]]] = fields[1]\n",
    "        \n",
    "        wf.write(basename[:-4] + \"\\t\" + \"\\t\".join(counts_list) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e39a06",
   "metadata": {},
   "source": [
    "### Normalize term counts by number of protein coding genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8404a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "genome_sizes = pd.read_csv(\n",
    "    \"results/2_JGIgold_KEGG_anayses_out/05_genome_feature_matrix.tsv\", \n",
    "    sep=\"\\t\", \n",
    "    usecols=[\"accession\", \"genes_proteinCoding\"],\n",
    "    index_col=\"accession\",\n",
    ")\n",
    "\n",
    "with open(\"results/3_GO_analyses/ubiquitous_counts_table.txt\", \"r\", newline=\"\") as rf, \\\n",
    "     open(\"results/3_GO_analyses/ubiquitous_counts_table_normalized.txt\", \"w\") as wf:\n",
    "    wf.write(next(rf))\n",
    "    reader = csv.reader(rf, delimiter=\"\\t\")\n",
    "    for row in reader:\n",
    "        accession = row[0]\n",
    "        if accession in genome_sizes.index:\n",
    "            ngenes = int(genome_sizes.at[accession, \"genes_proteinCoding\"])\n",
    "            wf.write(accession + \"\\t\" + \"\\t\".join([str(int(count) / ngenes) for count in row[1:]]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cacefa7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pangenome)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
